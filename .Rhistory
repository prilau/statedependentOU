left_edge  = which(edge[,1] == node_index)[1] # index of left child edge
right_edge = which(edge[,1] == node_index)[2] # index of right child edge
left = edge[left_edge,2] # index of left child node
right = edge[right_edge,2] # index of right child node
output_left <- postorder(left, edge, tree, continuousChar,
μ, V, log_norm_factor, branch_lengths, alpha, sigma2, theta)
μ <- output_left[[1]]
V <- output_left[[2]]
log_norm_factor <- output_left[[3]]
output_right <- postorder(right, edge, tree, continuousChar,
μ, V, log_norm_factor, branch_lengths, alpha, sigma2, theta)
μ <- output_right[[1]]
V <- output_right[[2]]
log_norm_factor <- output_right[[3]]
bl_left = branch_lengths[left_edge] # all branch of left child edge
bl_right = branch_lengths[right_edge] # all branch of right child edge
# 1) variance of the normal variable: this branch (v_left) and the subtree (V[left])
v_left = sigma2/(2*alpha) *expm1(2.0*alpha*bl_left)
var_left = v_left + V[left] * exp(2.0 * alpha * bl_left)
v_right = sigma2/(2*alpha) *expm1(2.0*alpha*bl_right)
var_right = v_right + V[right] * exp(2.0 * alpha * bl_right)
# 2) mean of the normal variable
mean_left = exp(alpha*bl_left)*(μ[left] - theta) + theta
mean_right = exp(alpha*bl_right)*(μ[right] - theta) + theta
## compute the mean and variance of the node
mean_ancestor = (mean_left * var_right + mean_right * var_left) / (var_left + var_right)
μ[node_index] = mean_ancestor
var_node = (var_left * var_right) / (var_left + var_right)
V[node_index] = var_node
## compute the normalizing factor, the left-hand side of the pdf of the normal variable
log_nf_left = bl_left * alpha
log_nf_right = bl_right * alpha
contrast = mean_left - mean_right
a = -(contrast*contrast / (2*(var_left+var_right)))
b = log(2*pi*(var_left+var_right))/2.0
#b = log(2*pi)/2.0 + log(var_left+var_right)/2.0
log_nf = log_nf_left + log_nf_right + a - b
log_norm_factor[node_index] = log_nf
return(list(μ, V, log_norm_factor))
}
# if is tip
else{
#edge_index = which(edge[,2] == node_index) # find edge index by tip node index
#subedge = tree$maps[[edge_index]]
species = tree$tip.label[node_index]
μ[node_index] = as.numeric(continuousChar[[which(names(continuousChar) == species)]])
V[node_index] = 0.0 ## if there is no observation error
return(list(μ, V, log_norm_factor))
}
}
## Pruning method (stateless)
logL_pruning <- function(tree, continuousChar, alpha, sigma2, theta){
ntip = length(tree$tip.label) # number of tips
edge = tree$edge # equals tree[:edge] in Julia
n_edges = length(edge[,1]) # number of edges
max_node_index = max(tree$edge) # total number of nodes
V = numeric(max_node_index)
μ = numeric(max_node_index)
log_norm_factor = numeric(max_node_index)
branch_lengths = tree$edge.length
root_index = ntip + 1
output <- postorder(root_index, edge, tree, continuousChar,
μ, V, log_norm_factor, branch_lengths, alpha, sigma2, theta)
μ <- output[[1]]
V <- output[[2]]
log_norm_factor <- output[[3]]
## assume root value equal to theta
μ_root = μ[root_index]
v_root = V[root_index]
lnl = dnorm(theta, mean = μ_root, sd = sqrt(v_root), log = TRUE) # are \theta and \mu in correct positions?
## add norm factor
for (log_nf in log_norm_factor){
lnl = lnl + log_nf
}
return(lnl)
}
logL_pruning(tree, brain, alpha=1, sigma2=1, theta=0)
devtools::install_github("OUwie")
?devtools::install_github
remotes::install_github("thej022214/OUwie")
pruning_likelihoods = c()
#vcv_likelihoods = c()
for (i in 1:10){
tree <- all_trees[[i]]
alpha = c(parameter_csv$alpha_Br[i], parameter_csv$alpha_Gr[i], parameter_csv$alpha_MF[i])
names(alpha) = c("Br", "MF", "Gr")
sigma2 = c(parameter_csv$sigma2_Br[i], parameter_csv$sigma2_Gr[i], parameter_csv$sigma2_MF[i])
names(sigma2) = c("Br", "MF", "Gr")
theta = c(parameter_csv$theta_Br[i], parameter_csv$theta_Gr[i], parameter_csv$theta_MF[i])
names(theta) = c("Br", "MF", "Gr")
pruning_likelihoods[i] <- sd_logL_pruning(tree, brain, alpha, sigma2, theta)
#vcv_likelihoods[i] <- sd_logL_vcv(tree, brain, alpha, sigma2, theta)
}
pruning_likelihoods
pruning_likelihoods = c()
#vcv_likelihoods = c()
for (i in 1:10){
tree <- all_trees[[i]]
alpha = c(parameter_csv$alpha_Br[i], parameter_csv$alpha_Gr[i], parameter_csv$alpha_MF[i])
names(alpha) = c("MF", "Br", "Gr")
sigma2 = c(parameter_csv$sigma2_Br[i], parameter_csv$sigma2_Gr[i], parameter_csv$sigma2_MF[i])
names(sigma2) = c("MF", "Br", "Gr")
theta = c(parameter_csv$theta_Br[i], parameter_csv$theta_Gr[i], parameter_csv$theta_MF[i])
names(theta) = c("MF", "Br", "Gr")
pruning_likelihoods[i] <- sd_logL_pruning(tree, brain, alpha, sigma2, theta)
#vcv_likelihoods[i] <- sd_logL_vcv(tree, brain, alpha, sigma2, theta)
}
pruning_likelihoods
pruning_likelihoods = c()
#vcv_likelihoods = c()
for (i in 1:10){
tree <- all_trees[[i]]
alpha = c(parameter_csv$alpha_Br[i], parameter_csv$alpha_Gr[i], parameter_csv$alpha_MF[i])
names(alpha) = c("MF", "Gr", "Br")
sigma2 = c(parameter_csv$sigma2_Br[i], parameter_csv$sigma2_Gr[i], parameter_csv$sigma2_MF[i])
names(sigma2) = c("MF", "Gr", "Br")
theta = c(parameter_csv$theta_Br[i], parameter_csv$theta_Gr[i], parameter_csv$theta_MF[i])
names(theta) = c("MF", "Gr", "Br")
pruning_likelihoods[i] <- sd_logL_pruning(tree, brain, alpha, sigma2, theta)
#vcv_likelihoods[i] <- sd_logL_vcv(tree, brain, alpha, sigma2, theta)
}
pruning_likelihoods
pruning_likelihoods = c()
#vcv_likelihoods = c()
for (i in 1:10){
tree <- all_trees[[i]]
alpha = c(parameter_csv$alpha_Br[i], parameter_csv$alpha_Gr[i], parameter_csv$alpha_MF[i])
names(alpha) = c("Gr", "MF", "Br")
sigma2 = c(parameter_csv$sigma2_Br[i], parameter_csv$sigma2_Gr[i], parameter_csv$sigma2_MF[i])
names(sigma2) = c("Gr", "MF", "Br")
theta = c(parameter_csv$theta_Br[i], parameter_csv$theta_Gr[i], parameter_csv$theta_MF[i])
names(theta) = c("Gr", "MF", "Br")
pruning_likelihoods[i] <- sd_logL_pruning(tree, brain, alpha, sigma2, theta)
#vcv_likelihoods[i] <- sd_logL_vcv(tree, brain, alpha, sigma2, theta)
}
pruning_likelihoods
pruning_likelihoods = c()
#vcv_likelihoods = c()
for (i in 1:10){
tree <- all_trees[[i]]
alpha = c(parameter_csv$alpha_Br[i], parameter_csv$alpha_Gr[i], parameter_csv$alpha_MF[i])
names(alpha) = c("Gr", "Br", "MF")
sigma2 = c(parameter_csv$sigma2_Br[i], parameter_csv$sigma2_Gr[i], parameter_csv$sigma2_MF[i])
names(sigma2) = c("Gr", "Br", "MF")
theta = c(parameter_csv$theta_Br[i], parameter_csv$theta_Gr[i], parameter_csv$theta_MF[i])
names(theta) = c("Gr", "Br", "MF")
pruning_likelihoods[i] <- sd_logL_pruning(tree, brain, alpha, sigma2, theta)
#vcv_likelihoods[i] <- sd_logL_vcv(tree, brain, alpha, sigma2, theta)
}
pruning_likelihoods
pruning_likelihoods = c()
#vcv_likelihoods = c()
for (i in 1:10){
tree <- all_trees[[i]]
#alpha = c(parameter_csv$alpha_Br[i], parameter_csv$alpha_Gr[i], parameter_csv$alpha_MF[i])
alpha = c(1,1,1)
names(alpha) = c("Br", "Gr", "MF")
#sigma2 = c(parameter_csv$sigma2_Br[i], parameter_csv$sigma2_Gr[i], parameter_csv$sigma2_MF[i])
sigma2 = c(1,1,1)
names(sigma2) = c("Br", "Gr", "MF")
#theta = c(parameter_csv$theta_Br[i], parameter_csv$theta_Gr[i], parameter_csv$theta_MF[i])
theta = c(0,0,0)
names(theta) = c("Br", "Gr", "MF")
pruning_likelihoods[i] <- sd_logL_pruning(tree, brain, alpha, sigma2, theta)
#vcv_likelihoods[i] <- sd_logL_vcv(tree, brain, alpha, sigma2, theta)
}
pruning_likelihoods
pruning_likelihoods = c()
#vcv_likelihoods = c()
for (i in 1:10){
tree <- all_trees[[i]]
alpha = c(parameter_csv$alpha_Br[i], parameter_csv$alpha_Gr[i], parameter_csv$alpha_MF[i])
names(alpha) = c("Br", "Gr", "MF")
sigma2 = c(parameter_csv$sigma2_Br[i], parameter_csv$sigma2_Gr[i], parameter_csv$sigma2_MF[i])
names(sigma2) = c("Br", "Gr", "MF")
theta = c(parameter_csv$theta_Br[i], parameter_csv$theta_Gr[i], parameter_csv$theta_MF[i])
names(theta) = c("Br", "Gr", "MF")
pruning_likelihoods[i] <- sd_logL_pruning(tree, brain, alpha, sigma2, theta)
#vcv_likelihoods[i] <- sd_logL_vcv(tree, brain, alpha, sigma2, theta)
}
pruning_likelihoods
# copy of state-dependent pruning function
sd_postorder <- function(node_index, edge, tree, continuousChar,
μ, V, log_norm_factor, subedges_lengths, alpha, sigma2, theta){
ntip = length(tree$tip.label)
# if is internal node
if (node_index > ntip){
left_edge  = which(edge[,1] == node_index)[1] # index of left child edge
right_edge = which(edge[,1] == node_index)[2] # index of right child edge
left = edge[left_edge,2] # index of left child node
right = edge[right_edge,2] # index of right child node
output_left <- sd_postorder(left, edge, tree, continuousChar,
μ, V, log_norm_factor, subedges_lengths, alpha, sigma2, theta)
μ <- output_left[[1]]
V <- output_left[[2]]
log_norm_factor <- output_left[[3]]
output_right <- sd_postorder(right, edge, tree, continuousChar,
μ, V, log_norm_factor, subedges_lengths, alpha, sigma2, theta)
μ <- output_right[[1]]
V <- output_right[[2]]
log_norm_factor <- output_right[[3]]
sub_bl_left = subedges_lengths[[left_edge]] # all subedges of left child edge
sub_bl_right = subedges_lengths[[right_edge]] # all subedges of right child edge
# for the sake of readability, computation of variance, mean, and log_nf are done in separate loops
# 1) variance of the normal variable: this branch (v_left) and the subtree (V[left])
## Is 'delta_left* exp(2.0 * alpha * bl_left)' added in each sub-edge?
delta_left = V[left]
v_left = 0 # initialise v_left
for (i in rev(1:length(sub_bl_left))){
state <- names(sub_bl_left[i])
v_left = sigma2[[state]]/(2*alpha[[state]]) *expm1(2.0*alpha[[state]]
*sub_bl_left[[i]])
delta_left = v_left + delta_left * exp(2.0 * alpha[[state]] * sub_bl_left[[i]])
}
delta_right = V[right]
v_right = 0 # initialise v_right
for (i in rev(1:length(sub_bl_right))){
state <- names(sub_bl_right[i])
v_right = sigma2[[state]]/(2*alpha[[state]]) *expm1(2.0*alpha[[state]]*sub_bl_right[[i]])
delta_right = v_right + delta_right * exp(2.0 * alpha[[state]] * sub_bl_right[[i]])
}
var_left = delta_left
var_right = delta_right
# 2) mean of the normal variable
mean_left = μ[left]
for (i in rev(1:length(sub_bl_left))){
state <- names(sub_bl_left[i])
mean_left = exp(alpha[[state]]*sub_bl_left[[i]])*(mean_left - theta[[state]]) + theta[[state]]
}
mean_right = μ[right]
for (i in rev(1:length(sub_bl_right))){
state <- names(sub_bl_right[i])
mean_right = exp(alpha[[state]]*sub_bl_right[[i]])*(mean_right - theta[[state]]) + theta[[state]]
}
## compute the mean and variance of the node
mean_ancestor = (mean_left * var_right + mean_right * var_left) / (var_left + var_right)
μ[node_index] = mean_ancestor
var_node = (var_left * var_right) / (var_left + var_right)
V[node_index] = var_node
## compute the normalizing factor, the left-hand side of the pdf of the normal variable
## this is the problem. I think in RevBayes we compute log_nf with the oldest sub-edge only
#log_nf_left = 0
#for (i in rev(1:length(sub_bl_left))){
#  state <- names(sub_bl_left[i])
#  log_nf_left = log_nf_left + sub_bl_left[[i]] * alpha[[state]]
#}
#log_nf_right = 0
#for (i in rev(1:length(sub_bl_right))){
#  state <- names(sub_bl_right[i])
#  log_nf_right = log_nf_right + sub_bl_right[[i]] * alpha[[state]]
#}
state <- names(sub_bl_left[1])
log_nf_left = log_nf_left + sub_bl_left[[1]] * alpha[[state]]
state <- names(sub_bl_right[1])
log_nf_right = log_nf_right + sub_bl_right[[1]] * alpha[[state]]
#state <- names(sub_bl_left[length(sub_bl_left)])
#log_nf_left = log_nf_left + sub_bl_left[[length(sub_bl_left)]] * alpha[[state]]
#state <- names(sub_bl_right[length(sub_bl_right)])
#log_nf_right = log_nf_right + sub_bl_right[[length(sub_bl_right)]] * alpha[[state]]
contrast = mean_left - mean_right
a = -(contrast*contrast / (2*(var_left+var_right)))
b = log(2*pi*(var_left+var_right))/2.0
#b = log(2*pi)/2.0 + log(var_left+var_right)/2.0
log_nf = log_nf_left + log_nf_right + a - b
log_norm_factor[node_index] = log_nf
return(list(μ, V, log_norm_factor))
}
# if is tip
else{
species = tree$tip.label[node_index]
μ[node_index] = as.numeric(continuousChar[[which(names(continuousChar) == species)]])
V[node_index] = 0.0 ## if there is no observation error
return(list(μ, V, log_norm_factor))
}
}
pruning_likelihoods = c()
#vcv_likelihoods = c()
for (i in 1:10){
tree <- all_trees[[i]]
#alpha = c(parameter_csv$alpha_Br[i], parameter_csv$alpha_Gr[i], parameter_csv$alpha_MF[i])
alpha = c(1,1,1)
names(alpha) = c("Br", "Gr", "MF")
#sigma2 = c(parameter_csv$sigma2_Br[i], parameter_csv$sigma2_Gr[i], parameter_csv$sigma2_MF[i])
sigma2 = c(1,1,1)
names(sigma2) = c("Br", "Gr", "MF")
#theta = c(parameter_csv$theta_Br[i], parameter_csv$theta_Gr[i], parameter_csv$theta_MF[i])
theta = c(0,0,0)
names(theta) = c("Br", "Gr", "MF")
pruning_likelihoods[i] <- sd_logL_pruning(tree, brain, alpha, sigma2, theta)
#vcv_likelihoods[i] <- sd_logL_vcv(tree, brain, alpha, sigma2, theta)
}
# copy of state-dependent pruning function
sd_postorder <- function(node_index, edge, tree, continuousChar,
μ, V, log_norm_factor, subedges_lengths, alpha, sigma2, theta){
ntip = length(tree$tip.label)
# if is internal node
if (node_index > ntip){
left_edge  = which(edge[,1] == node_index)[1] # index of left child edge
right_edge = which(edge[,1] == node_index)[2] # index of right child edge
left = edge[left_edge,2] # index of left child node
right = edge[right_edge,2] # index of right child node
output_left <- sd_postorder(left, edge, tree, continuousChar,
μ, V, log_norm_factor, subedges_lengths, alpha, sigma2, theta)
μ <- output_left[[1]]
V <- output_left[[2]]
log_norm_factor <- output_left[[3]]
output_right <- sd_postorder(right, edge, tree, continuousChar,
μ, V, log_norm_factor, subedges_lengths, alpha, sigma2, theta)
μ <- output_right[[1]]
V <- output_right[[2]]
log_norm_factor <- output_right[[3]]
sub_bl_left = subedges_lengths[[left_edge]] # all subedges of left child edge
sub_bl_right = subedges_lengths[[right_edge]] # all subedges of right child edge
# for the sake of readability, computation of variance, mean, and log_nf are done in separate loops
# 1) variance of the normal variable: this branch (v_left) and the subtree (V[left])
## Is 'delta_left* exp(2.0 * alpha * bl_left)' added in each sub-edge?
delta_left = V[left]
v_left = 0 # initialise v_left
for (i in rev(1:length(sub_bl_left))){
state <- names(sub_bl_left[i])
v_left = sigma2[[state]]/(2*alpha[[state]]) *expm1(2.0*alpha[[state]]
*sub_bl_left[[i]])
delta_left = v_left + delta_left * exp(2.0 * alpha[[state]] * sub_bl_left[[i]])
}
delta_right = V[right]
v_right = 0 # initialise v_right
for (i in rev(1:length(sub_bl_right))){
state <- names(sub_bl_right[i])
v_right = sigma2[[state]]/(2*alpha[[state]]) *expm1(2.0*alpha[[state]]*sub_bl_right[[i]])
delta_right = v_right + delta_right * exp(2.0 * alpha[[state]] * sub_bl_right[[i]])
}
var_left = delta_left
var_right = delta_right
# 2) mean of the normal variable
mean_left = μ[left]
for (i in rev(1:length(sub_bl_left))){
state <- names(sub_bl_left[i])
mean_left = exp(alpha[[state]]*sub_bl_left[[i]])*(mean_left - theta[[state]]) + theta[[state]]
}
mean_right = μ[right]
for (i in rev(1:length(sub_bl_right))){
state <- names(sub_bl_right[i])
mean_right = exp(alpha[[state]]*sub_bl_right[[i]])*(mean_right - theta[[state]]) + theta[[state]]
}
## compute the mean and variance of the node
mean_ancestor = (mean_left * var_right + mean_right * var_left) / (var_left + var_right)
μ[node_index] = mean_ancestor
var_node = (var_left * var_right) / (var_left + var_right)
V[node_index] = var_node
## compute the normalizing factor, the left-hand side of the pdf of the normal variable
## this is the problem. I think in RevBayes we compute log_nf with the oldest sub-edge only
#log_nf_left = 0
#for (i in rev(1:length(sub_bl_left))){
#  state <- names(sub_bl_left[i])
#  log_nf_left = log_nf_left + sub_bl_left[[i]] * alpha[[state]]
#}
#log_nf_right = 0
#for (i in rev(1:length(sub_bl_right))){
#  state <- names(sub_bl_right[i])
#  log_nf_right = log_nf_right + sub_bl_right[[i]] * alpha[[state]]
#}
state <- names(sub_bl_left[1])
log_nf_left = sub_bl_left[[1]] * alpha[[state]]
state <- names(sub_bl_right[1])
log_nf_right = sub_bl_right[[1]] * alpha[[state]]
#state <- names(sub_bl_left[length(sub_bl_left)])
#log_nf_left = log_nf_left + sub_bl_left[[length(sub_bl_left)]] * alpha[[state]]
#state <- names(sub_bl_right[length(sub_bl_right)])
#log_nf_right = log_nf_right + sub_bl_right[[length(sub_bl_right)]] * alpha[[state]]
contrast = mean_left - mean_right
a = -(contrast*contrast / (2*(var_left+var_right)))
b = log(2*pi*(var_left+var_right))/2.0
#b = log(2*pi)/2.0 + log(var_left+var_right)/2.0
log_nf = log_nf_left + log_nf_right + a - b
log_norm_factor[node_index] = log_nf
return(list(μ, V, log_norm_factor))
}
# if is tip
else{
species = tree$tip.label[node_index]
μ[node_index] = as.numeric(continuousChar[[which(names(continuousChar) == species)]])
V[node_index] = 0.0 ## if there is no observation error
return(list(μ, V, log_norm_factor))
}
}
pruning_likelihoods = c()
#vcv_likelihoods = c()
for (i in 1:10){
tree <- all_trees[[i]]
alpha = c(parameter_csv$alpha_Br[i], parameter_csv$alpha_Gr[i], parameter_csv$alpha_MF[i])
names(alpha) = c("Br", "Gr", "MF")
sigma2 = c(parameter_csv$sigma2_Br[i], parameter_csv$sigma2_Gr[i], parameter_csv$sigma2_MF[i])
names(sigma2) = c("Br", "Gr", "MF")
theta = c(parameter_csv$theta_Br[i], parameter_csv$theta_Gr[i], parameter_csv$theta_MF[i])
names(theta) = c("Br", "Gr", "MF")
pruning_likelihoods[i] <- sd_logL_pruning(tree, brain, alpha, sigma2, theta)
#vcv_likelihoods[i] <- sd_logL_vcv(tree, brain, alpha, sigma2, theta)
}
pruning_likelihoods
#vcv_likelihoods = c()
for (i in 1:10){
tree <- all_trees[[i]]
alpha = c(parameter_csv$alpha_Br[i], parameter_csv$alpha_Gr[i], parameter_csv$alpha_MF[i])
names(alpha) = c("Gr", "Br", "MF")
sigma2 = c(parameter_csv$sigma2_Br[i], parameter_csv$sigma2_Gr[i], parameter_csv$sigma2_MF[i])
names(sigma2) = c("Gr", "Br", "MF")
theta = c(parameter_csv$theta_Br[i], parameter_csv$theta_Gr[i], parameter_csv$theta_MF[i])
names(theta) = c("Gr", "Br", "MF")
pruning_likelihoods[i] <- sd_logL_pruning(tree, brain, alpha, sigma2, theta)
#vcv_likelihoods[i] <- sd_logL_vcv(tree, brain, alpha, sigma2, theta)
}
pruning_likelihoods
# copy of state-dependent pruning function
sd_postorder <- function(node_index, edge, tree, continuousChar,
μ, V, log_norm_factor, subedges_lengths, alpha, sigma2, theta){
ntip = length(tree$tip.label)
# if is internal node
if (node_index > ntip){
left_edge  = which(edge[,1] == node_index)[1] # index of left child edge
right_edge = which(edge[,1] == node_index)[2] # index of right child edge
left = edge[left_edge,2] # index of left child node
right = edge[right_edge,2] # index of right child node
output_left <- sd_postorder(left, edge, tree, continuousChar,
μ, V, log_norm_factor, subedges_lengths, alpha, sigma2, theta)
μ <- output_left[[1]]
V <- output_left[[2]]
log_norm_factor <- output_left[[3]]
output_right <- sd_postorder(right, edge, tree, continuousChar,
μ, V, log_norm_factor, subedges_lengths, alpha, sigma2, theta)
μ <- output_right[[1]]
V <- output_right[[2]]
log_norm_factor <- output_right[[3]]
sub_bl_left = subedges_lengths[[left_edge]] # all subedges of left child edge
sub_bl_right = subedges_lengths[[right_edge]] # all subedges of right child edge
# for the sake of readability, computation of variance, mean, and log_nf are done in separate loops
# 1) variance of the normal variable: this branch (v_left) and the subtree (V[left])
## Is 'delta_left* exp(2.0 * alpha * bl_left)' added in each sub-edge?
delta_left = V[left]
v_left = 0 # initialise v_left
for (i in rev(1:length(sub_bl_left))){
state <- names(sub_bl_left[i])
v_left = sigma2[[state]]/(2*alpha[[state]]) *expm1(2.0*alpha[[state]]
*sub_bl_left[[i]])
delta_left = v_left + delta_left * exp(2.0 * alpha[[state]] * sub_bl_left[[i]])
}
delta_right = V[right]
v_right = 0 # initialise v_right
for (i in rev(1:length(sub_bl_right))){
state <- names(sub_bl_right[i])
v_right = sigma2[[state]]/(2*alpha[[state]]) *expm1(2.0*alpha[[state]]*sub_bl_right[[i]])
delta_right = v_right + delta_right * exp(2.0 * alpha[[state]] * sub_bl_right[[i]])
}
var_left = delta_left
var_right = delta_right
# 2) mean of the normal variable
mean_left = μ[left]
for (i in rev(1:length(sub_bl_left))){
state <- names(sub_bl_left[i])
mean_left = exp(alpha[[state]]*sub_bl_left[[i]])*(mean_left - theta[[state]]) + theta[[state]]
}
mean_right = μ[right]
for (i in rev(1:length(sub_bl_right))){
state <- names(sub_bl_right[i])
mean_right = exp(alpha[[state]]*sub_bl_right[[i]])*(mean_right - theta[[state]]) + theta[[state]]
}
## compute the mean and variance of the node
mean_ancestor = (mean_left * var_right + mean_right * var_left) / (var_left + var_right)
μ[node_index] = mean_ancestor
var_node = (var_left * var_right) / (var_left + var_right)
V[node_index] = var_node
## compute the normalizing factor, the left-hand side of the pdf of the normal variable
## this is the problem. I think in RevBayes we compute log_nf with the oldest sub-edge only
log_nf_left = 0
for (i in rev(1:length(sub_bl_left))){
state <- names(sub_bl_left[i])
log_nf_left = log_nf_left + sub_bl_left[[i]] * alpha[[state]]
}
log_nf_right = 0
for (i in rev(1:length(sub_bl_right))){
state <- names(sub_bl_right[i])
log_nf_right = log_nf_right + sub_bl_right[[i]] * alpha[[state]]
}
contrast = mean_left - mean_right
a = -(contrast*contrast / (2*(var_left+var_right)))
b = log(2*pi*(var_left+var_right))/2.0
#b = log(2*pi)/2.0 + log(var_left+var_right)/2.0
log_nf = log_nf_left + log_nf_right + a - b
log_norm_factor[node_index] = log_nf
return(list(μ, V, log_norm_factor))
}
# if is tip
else{
species = tree$tip.label[node_index]
μ[node_index] = as.numeric(continuousChar[[which(names(continuousChar) == species)]])
V[node_index] = 0.0 ## if there is no observation error
return(list(μ, V, log_norm_factor))
}
}
pruning_likelihoods = c()
#vcv_likelihoods = c()
for (i in 1:10){
tree <- all_trees[[i]]
alpha = c(parameter_csv$alpha_Br[i], parameter_csv$alpha_Gr[i], parameter_csv$alpha_MF[i])
names(alpha) = c("Br", "Gr", "MF")
sigma2 = c(parameter_csv$sigma2_Br[i], parameter_csv$sigma2_Gr[i], parameter_csv$sigma2_MF[i])
names(sigma2) = c("Br", "Gr", "MF")
theta = c(parameter_csv$theta_Br[i], parameter_csv$theta_Gr[i], parameter_csv$theta_MF[i])
names(theta) = c("Br", "Gr", "MF")
pruning_likelihoods[i] <- sd_logL_pruning(tree, brain, alpha, sigma2, theta)
#vcv_likelihoods[i] <- sd_logL_vcv(tree, brain, alpha, sigma2, theta)
}
pruning_likelihoods
